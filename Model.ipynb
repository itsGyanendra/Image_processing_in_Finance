{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTU8IEC5KT7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "seed_value= 0\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "#tf.random.set_seed(seed_value)\n",
        "tf.compat.v1.set_random_seed(seed_value)\n",
        "\n",
        "from keras import backend as K\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "tf.compat.v1.keras.backend.set_session(sess)\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import chain \n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmF7xLmHKhrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join('Reliance', 'Train') #Just the directory of training_images\n",
        "validation_dir = os.path.join('Reliance', 'Validation') #Just the directory of valiadtion_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQbDuksfKwU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2=pd.read_csv(\"testing.csv\")  #test-set  for financial evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4bAyHXfK7_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_buy_dir = os.path.join(train_dir, 'Buy')  # directory with our training  Buy pictures\n",
        "train_hold_dir = os.path.join(train_dir, 'Hold')  # directory with our training Hold pictures\n",
        "train_sell_dir = os.path.join(train_dir, 'Sell')  # directory with our training Sell pictures\n",
        "validation_buy_dir = os.path.join(validation_dir, 'Buy')  # directory with our validation Buy pictures\n",
        "validation_hold_dir = os.path.join(validation_dir, 'Hold')  # directory with our validation Hold pictures\n",
        "validation_sell_dir = os.path.join(validation_dir, 'Sell')  # directory with our validation Sell pictures\n",
        "\n",
        "num_buy_tr = len(os.listdir(train_buy_dir))\n",
        "num_hold_tr = len(os.listdir(train_hold_dir))\n",
        "num_sell_tr = len(os.listdir(train_sell_dir))\n",
        "\n",
        "num_buy_val = len(os.listdir(validation_buy_dir))\n",
        "num_hold_val = len(os.listdir(validation_hold_dir))\n",
        "num_sell_val = len(os.listdir(validation_sell_dir))\n",
        "\n",
        "total_train = num_buy_tr + num_hold_tr + num_sell_tr\n",
        "total_val = num_buy_val + num_hold_val + num_sell_val\n",
        "\n",
        "\n",
        "\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60obDDFzLEbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 100\n",
        "IMG_HEIGHT = 12\n",
        "IMG_WIDTH = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmDmet36NHRF",
        "colab_type": "text"
      },
      "source": [
        "# ***Data Augmentation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWN3IhiSLIzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "#tf.keras.preprocessing.image_dataset_from_directory(train_dir,)\n",
        "image_gen_train = ImageDataGenerator(\n",
        "    rescale=1./255,featurewise_center=True,\n",
        "    \n",
        "    width_shift_range=0.1,\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='reflect',\n",
        "    )\n",
        "\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data_gen =image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,color_mode=\"rgb\",\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='sparse')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjIadl8kLX1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,color_mode=\"rgb\",\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='sparse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJMqn0huM_XL",
        "colab_type": "text"
      },
      "source": [
        "# ***Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j2Xp6oLLYv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras import regularizers\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(12,15,3)),\n",
        "        layers.Conv2D(32,kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.Conv2D(64,kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.25,seed=0),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(3, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "model.compile(optimizer='rmsprop',\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LROqBcGxM2Dx",
        "colab_type": "text"
      },
      "source": [
        "# ***Computational Performance***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc7sjo-JLh6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-xaUMCyL3M-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_loss,val_acc =model.evaluate(val_data_gen,steps=len(test_data_gen),verbose=0)\n",
        "val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSqmJomJLi3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='acc')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.2, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbq3q12FLrIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_test = ImageDataGenerator(rescale=1./255)\n",
        "test_data_gen = image_gen_test.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory='Testing',\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='sparse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXKoMmiLLz0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss,test_acc =model.evaluate(test_data_gen,steps=len(test_data_gen),verbose=0)\n",
        "test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn5D5lYTMZj5",
        "colab_type": "text"
      },
      "source": [
        "## ***Financial Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIM59JdpMKka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "labels_pred=[]\n",
        "\n",
        "PATH = os.getcwd()\n",
        "data_path =  'Testing'\n",
        "data_dir_list = os.listdir(data_path)\n",
        "\n",
        "img_data_list=[]\n",
        "for dataset in data_dir_list:\n",
        "    img_list=os.listdir(data_path+'/'+ dataset)\n",
        "    for img in img_list:\n",
        "        img_path = data_path + '/'+ dataset + '/'+ img\n",
        "        img = keras.preprocessing.image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "        test_img = image.img_to_array(img)/255\n",
        "        test_img=np.array(test_img)\n",
        "        img_array = tf.expand_dims(test_img, 0)  # Create batch axis\n",
        "        labels_pred.append(np.argmax(model.predict(img_array),axis=1)[0])\n",
        "        \n",
        "print(labels_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcEyjDDLMQsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2['prediction']=labels_pred\n",
        "icost=[]\n",
        "buy_l=[]\n",
        "cost=0\n",
        "buy_c=0\n",
        "buy=0\n",
        "sell=0\n",
        "win=0\n",
        "loss=0\n",
        "\n",
        "for i in df2.index:\n",
        "    if(df2['prediction'][i]==0):\n",
        "        if(buy_c<=0):\n",
        "            buy_c=buy_c+1\n",
        "            buy=buy+1\n",
        "            cost=cost - df2['Adj Close'][i]\n",
        "            x=df2['Adj Close'][i]\n",
        "            #print(cost)\n",
        "            buy_l.append(x)\n",
        "            print(\"date : {}, cost : {},buy_c:{},price:{}\".format(i, cost,buy_c,x),'Buy')\n",
        "    if(df2['prediction'][i]==2):\n",
        "        y=df2['Adj Close'][i]\n",
        "        if(buy_c>=1):\n",
        "            if(y-x>0):\n",
        "                buy_c=buy_c-1\n",
        "                sell=sell+1\n",
        "                cost=cost+df2['Adj Close'][i]\n",
        "                print(\"date : {}, cost :{},buy_c:{},price:{}\".format(i, cost,buy_c,y),\"Sell\")\n",
        "                if((buy>0) & (sell>0)):\n",
        "                    if(y-x<0):\n",
        "                        loss=loss+1\n",
        "                    if(y-x>0):\n",
        "                        win=win+1\n",
        "                    icost.append(y-x)\n",
        "    if(df2['prediction'][i]==1):\n",
        "        continue\n",
        "    \n",
        "    \n",
        "    \n",
        "  \n",
        "print(cost)\n",
        "#print((cost-icost)/icost)\n",
        "print(buy)\n",
        "print(sell)\n",
        "print(\"win:\",win)\n",
        "print('loss:',loss)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}